---
title: "Machine Learning"
author: "Daniel Stein (dcstein2)"
date: "30/01/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## This part needs to be Deleted in your own Report!

This is a **Sample Report** for your first problem set. No answers are provided (maybe some tips). Feel free to use this template to submit your own Report! For those who have used R Markdown before and have their own templates, feel free to use them, but first read this one!  

Some usefull Links for **R Markdown**: 

a) [Intro to R Markdown](https://rmarkdown.rstudio.com/articles_intro.html)
b) [Basic Syntax](https://www.markdownguide.org/basic-syntax/)
c) [Intro to Markdown](https://learninglab.gitlabpages.inria.fr/mooc-rr/mooc-rr-ressources/module1/ressources/introduction_to_markdown.html)
d) Don't forget to use **Google** when you code! Just make sure you type the correct  question! 

Some usefull Notes:

a) Nobody expects from you to include the Questions in your reports. Only the Answers are going to be evaluated. Here the Questions are provided just to get you familiar with R Markdown (feel free to delete them in your own report).
b) If you are new to R Markdown, don't wait the last day to write your report. Start early!
c) In the name of your .zip folder and .Rmd file your own NetID is expected, in the "author" section your own name and NetID is also expected.
d) Make sure your R code runs before you add it in your .Rmd file.

**Finally, you are going to submit TWO files: your Report in an .html format and the a .zip folder that contains everything you used to create it (the .Rmd file and the images). Make sure your code in the .Rmd file runs properly before submitting everything!** 


# Question 1 (concept)[20p]

For each of parts (a) through (d), indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible method. Justify your answer.

a) The sample size $n$ is extremely large, and the number of predictors $p$ is small.

b) The number of predictors $p$ is extremely large, and the number of observations $n$ is small.

c) The relationship between the predictors and response is highly non-linear.

d) The variance of the error terms, $Var(\epsilon)$, is extremely high.

# Answer 1

a) When the sample size is large and the number of independent variables are small, I expect a flexible statistical learning method to be better  because $\hat{f}(x_{0})$ would fit the data better due to a larger sample size.

b) When $p>n$, a flexible learning method is worse because of overfitting the data. This will result in a high test $MSE$.

c) The flexible learning method would be better if the relationship between the predictors and the response is highly non-linear. Flexible learning methods eliminate bias in the estimates for non-linear relationships whereas inflexible methods will have extremely high bias and high variance. 

d) A high variance in the irreducible error term will make a flexible learning method worse because flexible learning methods will try and predict the random noise element causing high variance in $\hat{f}(x_{0})$.


# Question 2 (concept)[10p]
Explain whether each scenario is a classification or regression problem, and indicate
whether we are most interested in inference or prediction. Finally, provide $n$ and $p$.

a) We collect a set of data on the top 500 firms in the US. For each firm we record
profit, number of employees, industry and the CEO salary. We are interested in
understanding which factors affect CEO salary.
b) We are considering launching a new product and wish to know whether it will be
a _success_ or a _failure_. We collect data on 20 similar products that were previously
launched. For each product we have recorded whether it was a success or failure,
price charged for the product, marketing budget, competition price, and ten other
variables.
c) We are interested in predicting the % change in the USD/Euro exchange rate in
relation to the weekly changes in the world stock markets. Hence we collect weekly
data for all of 2012. For each week we record the % change in the USD/Euro, the
% change in the US market, the % change in the British market, and the % change
in the German market.

# Answer 2
a) This is a regression problem because we are trying to inference changes in CEO salary, hence the response variable is quantitative. $N=500,  P = 3$
b) This is a classification problem because the response variable is qualitative. $N=20, P=13$. Here we are interested  in prediction. 
c) Regression problem and we are interested in prediction. $N= 52, P = 3$.


# Question 3 (concept)[20p]
We now revisit the bias-variance decomposition.

a) Provide a sketch of typical (squared) bias, variance, training mean squared error,
test mean squared error, and Bayes (or irreducible) error rate curves, on a single
plot, as we go from less flexible statistical learning methods towards more flexible
approaches. The $x$-axis should represent the amount of flexibility in the method,
and the $y$-axis should represent the values for each curve. There should be five
curves. Make sure to label each one.

b) Explain why each of the five curves has the shape displayed in part (a)

# Answer 3
a) Here, either you're going to sketch the graph, take a picture and attach it (make sure you are using the right file format, for example it could be .jpg or .png), this way:

![Question 3 Graph](C:/Users/dcste/OneDrive/Senior_Year_Second_Semester/Econ_490/Homework/Econ_490_HW/Question_3.jpg){width=.2in}
 



b) *Typical squared bias* always decreases as flexibility increases because flexible learning methods can accurately estimate a real-life problem better than inflexible methods, especially when the true relationship is non-linear. *Training MSE** always declines as flexiblity grows  because bias continually declines which produces a better $\hat{f}(x_{1})$ to fit the training data. *Variance* always increases as flexibility grwos. For example, if the training or test data have a high variance, htne small changes in the data result in large changes in $\hat{f}$. *Test MSE* is U-shaped due to the relative rate of change in bias and variance. As flexibility increases, bias tends to fall faster than variance causing a decline in test MSE, however, beyone a certain point increasing flexibility does little to change the bias so the variance increases significantly, causing test MSE to increase. 

# Question 4 (concept)[20p]
The table below provides a training data set containing six observations, three predictors, and one qualitative response variable 

+------+-------+-------+-------+-------+
| Obs. | $X_1$ | $X_2$ | $X_3$ |  $Y$  |
+======+=======+=======+=======+=======+
|  1)  |   0   |   3   |   0   | Red   |
+------+-------+-------+-------+-------+
|  2)  |   2   |   0   |   0   | Red   |
+------+-------+-------+-------+-------+
|  3)  |   0   |   1   |   3   | Red   |
+------+-------+-------+-------+-------+
|  4)  |   0   |   1   |   2   | Green |
+------+-------+-------+-------+-------+
|  5)  |  -1   |   0   |   1   | Green |
+------+-------+-------+-------+-------+
|  6)  |   1   |   1   |   1   | Red   |
+------+-------+-------+-------+-------+

Suppose we wish to use this data set to make a prediction for $Y$ when $X_1 = X_2 = X_3 = 0$ using K-nearest neighbors.

(a) Compute the Euclidean distance between each observation and the test point, $X_1 = X_2 = X_3 = 0$.

(Note: the Euclidean distance of two vectors $a = (a_1,a_2,a_3)$ and $b = (b_1,b_2,b_3)$ is
given by $d(a,b) = \sqrt{(a_1-b_1)^2 + (a_2-b_2)^2 + (a_3-b_3)^2}$. The same idea extends to vectors with $n$ coordinates.)

b) What is our prediction with K = 1? Why?
c) What is our prediction with K = 3? Why?
d) If the Bayes decision boundary in this problem is highly non-linear, then would we
expect the best value for K to be large or small? Why?

# Answer 4
a) Here it would be recommended to create a table (or choose any way want to provide your answer):

+------+-------+-------+-------+----------------------------+
| Obs. | $X_1$ | $X_2$ | $X_3$ | $d\big(obs, (0,0,0) \big)$ |
+======+=======+=======+=======+============================+
|  1)  |   0   |   3   |   0   |              3           |
+------+-------+-------+-------+----------------------------+
|  2)  |   2   |   0   |   0   |              2             |
+------+-------+-------+-------+----------------------------+
|  3)  |   0   |   1   |   3   |              3.162             |
+------+-------+-------+-------+----------------------------+
|  4)  |   0   |   1   |   2   |              2.236             |
+------+-------+-------+-------+----------------------------+
|  5)  |  -1   |   0   |   1   |              1.414          |
+------+-------+-------+-------+----------------------------+
|  6)  |   1   |   1   |   1   |              1.732         |
+------+-------+-------+-------+----------------------------+

b) 

$\Pr(Y=green|X=x_{0})$ = $\frac{1}{1}\sum_{i= N_{0}}^{i} I(Y_{i}=Green)$ equals 1.

$\Pr(Y=Red|X=x_{0})$ = $\frac{1}{1}\sum_{i= N_{0}}^{i} I(Y_{i}=Red)$ equals 0.

The shortest distance from the vector $ [0,0,0]$ is observation 5, which was green. 


c) $\Pr(Y=green|X=x_{0})$ = $\frac{1}{3}\sum_{i= N_{0}}^{i} I(Y_{i}=Green)$ equals $\frac{1}{3}$.

$\Pr(Y=Red|X=x_{0})$ = $\frac{1}{3}\sum_{i= N_{0}}^{i} I(Y_{i}=Red)$ equals $\frac{2}{3}$

Since $\frac{2}{3} > \frac{1}{3}$ our prediction with $K = 3$ is *red.*

d) If the Bayes decision boundary is highly non-linear, then we would expect the best value of K to be small since smaller values of K represent more flexible approaches for a classifcation setting. 


# Question 5 (applied)[30p for part (c)]
This exercise relates to the College data set, It contains a number of variables for 777 different universities and colleges in the US. The variables are

- Private: Public/private indicator
- Apps: Number of applications received
- Accept: Number of applicants accepted
- Enroll: Number of new students enrolled
- Top10perc: New students from top 10
- Top25perc: New students from top 25
- F.Undergrad: Number of full-time undergraduates
- P.Undergrad: Number of part-time undergraduates
- Outstate: Out-of-state tuition
- Room.Board: Room and board costs
- Books: Estimated book costs
- Personal: Estimated personal spending
- PhD: Percent of faculty with Ph.D.'s
- Terminal: Percent of faculty with terminal degree
- S.F.Ratio: Student/faculty ratio
- perc.alumni: Percent of alumni who donate
- Expend: Instructional expenditure per student
- Grad.Rate: Graduation rate



Before reading the data into R, it can be viewed in Excel or a text editor.

a) Use the read.csv() function to read the data into R. Call the loaded data college. Make sure that you have the directory set to the correct location for the data. The R commands getwd() and setwd() may be helpful.
```{r}
college <- read.csv("C:/Users/dcste/OneDrive/Senior_Year_Second_Semester/Econ_490/Homework/Econ_490_HW/College.csv",stringsAsFactors = T)
str(college)
```



b) Look at the data using the View() function. You should notice that the first column is just the name of each university. We don't really want R to treat this as data. However, it may be handy to have these names for later. Try the following commands:

```{r, eval=TRUE}

rownames(college) <- college[, 1]
View(college)
```

You should see that there is now a row.names column with the name of each university recorded. This means that R has given each row a name corresponding to the appropriate university. R will not try to perform calculations on the row names. However, we still need to eliminate the first column in the data where the names are stored. Try

```{r, eval=TRUE}
college <- college[, -1]
View(college)
```

Now you should see that the first data column is Private. Note that another column labeled row.names now appears before the Private column. However, this is not a data column but rather the name that R is giving to each row.

c) 
i. Use the summary() function to produce a numerical summary of the variables in
the data set.

```{r}
summary(college)

```




ii. Use the pairs() function to produce a scatterplot matrix of the first ten columns
or variables of the data. Recall that you can reference the first ten columns of a
matrix A using A[,1:10].

```{r}
pairs(college[,1:10])
```


iii. Use the plot() function to produce side-by-side boxplots of Outstate versus
Private.

```{r}
plot(college$Private,college$Outstate, main = "Out of State Tutition", xlab = "Private",ylab = "Tution", col = "cornflowerblue")
```



iv. Create a new qualitative variable, called Elite, by binning the Top10perc
variable. We are going to divide universities into two groups based on whether or
not the proportion of students coming from the top 10% of their high school classes
exceeds 50%.


```{r, eval=TRUE}
Elite <- rep("No", nrow(college))
Elite[college$Top10perc > 50] <- "Yes"
Elite_1 <- as.factor(Elite)
college <- data.frame(college, Elite_1)
str(college)

```

Use the summary() function to see how many elite universities there are. Now use the plot() function to produce side-by-side boxplots of Outstate versus Elite.

```{r}

plot(college$Elite,college$Outstate, main = "Out of State Tution", xlab = "Elite College", ylab = "Tution", col = "cornflowerblue")
```


v. Use the hist() function to produce some histograms with differing numbers of
bins for a few of the quantitative variables. You may find the command par(mfrow
= c(2, 2)) useful: it will divide the print window into four regions so that four
plots can be made simultaneously. Modifying the arguments to this function will
divide the screen in other ways.



```{r}
par(mfrow = c(3,2))
hist(college$perc.alumni,breaks = 100, col = "green")
hist(college$Top10perc, breaks = 50, col = "red")
hist(college$Books, breaks = 40, col = "yellow")
hist(college$Grad.Rate, col = "cornflowerblue")
hist(college$Expend,breaks = 50, col = "orange")

```



vi. Continue exploring the data, and provide a brief summary of what you discover.

```{r}
college_1 <- data.frame(exp = college$Expend,elite = Elite_1, num_phd = college$PhD,alumn_perc = college$perc.alumni, s_f_ratio = college$S.F.Ratio)
expend <- lm(exp~elite+num_phd+alumn_perc+s_f_ratio,data=college_1)
summary(expend)
names(college_1)

```

```{r}

library(moments)
library(knitr)


descriptive_statistics <- rbind(apply(college[,2:18],2,mean),
                                apply(college[,2:18],2,sd),
                                apply(college[,2:18],2,var),
                                apply(college[,2:18],2,skewness),
                                apply(college[,2:18],2,kurtosis))
descriptive_statistics <- round(descriptive_statistics,2)
rownames(descriptive_statistics) <- c("Mean", "Standard Deviation", "Variance", "Skewness", "Kurtosis")
descriptive_statistics

```


After exploring the data, I wanted to discover the average treatment effect of expenditure per student and going to an elite school. What I found was surprising. Holding the variables PHD, S/F Ratio, Percent Alumni who donate fixed, I found that the average instructional expenditure per student increases by $5663 dollars. According to the descriptive statistics above, this is approximately one full standard deviation higher than students who do not attend elite schools. Reasons why are most likely related to endowment levels and tuition levels.

